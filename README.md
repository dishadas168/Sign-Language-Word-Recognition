# Sign-Language-Word-Recognition
This project demonstrates the power of probabalistic models. A word recognizer for American Sign Language (ASL) video sequences is built. In particular, this project employs Hidden Markov Models to analyze a series of measurements taken from videos of American Sign Language (ASL) collected for research.

In each video, an ASL signer is signing a meaningful sentence. In a typical ASL recognition system, you observe the XY coordinates of the speaker's left hand, right hand, and nose for every frame. The following diagram shows how the positions of the left hand (Red), right hand (Blue), and nose (Green) change over time in video number #66. Saturation of colors represents time elapsed.

![Img1](/hands_nose_position.png)

# File Summary

submission.py: Contains main program in parts

hmm_submission_test.py: Unit tests for testing correct implementation of problems

notebook2script.py: Converts notebook to python submission file

notebook.ipynb: Executable notebook with instructions







