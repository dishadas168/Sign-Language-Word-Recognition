# Sign-Language-Word-Recognition
This project demonstrates the power of probabalistic models. A word recognizer for American Sign Language (ASL) video sequences is built. In particular, this project employs Hidden Markov Models to analyze a series of measurements taken from videos of American Sign Language (ASL) collected for research.

In each video, an ASL signer is signing a meaningful sentence. In a typical ASL recognition system, you observe the XY coordinates of the speaker's left hand, right hand, and nose for every frame. The following diagram shows how the positions of the left hand (Red), right hand (Blue), and nose (Green) change over time in video number #66. Saturation of colors represents time elapsed.

![Img1](/hands_nose_position.png)




